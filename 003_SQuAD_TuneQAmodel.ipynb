{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlinZohari/InformationExtraction/blob/main/003_SQuAD_TuneQAmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ha78KH0frS0"
      },
      "source": [
        "# Fine-Tuning QA model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg2fF-z4AVgI"
      },
      "source": [
        "This notebook are run in Google Colab to leverage its GPU capability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss08hKKUfrS1"
      },
      "source": [
        "Reference:\n",
        "1. Hugging Face -  [Question and Answering Task Guide](https://huggingface.co/docs/transformers/tasks/question_answering)\n",
        "2. Hugging face [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb) on Question Answering on SQUAD\n",
        "2. Creating Train and Validation Datasets - https://simpletransformers.ai/docs/qa-data-formats/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation GPU in Google Colab"
      ],
      "metadata": {
        "id": "T-6JjBOICsey"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9OAMAN7Qf0r",
        "outputId": "eb23abbf-6bf8-4cc1-fab3-810c27db6654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 29 07:50:32 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39dkGpjcQfn4",
        "outputId": "44cd67ef-f7d3-4d05-d3a7-227d71000ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PNDA2y8dqyJc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_SRPedNAVgN"
      },
      "source": [
        "Setting CUDA_LAUNCH_BLOCKING=1 makes all CUDA operations synchronous, which means the CPU will wait for the GPU to finish before executing the next line of code. This makes it easier to identify and debug errors, because the stack trace will show exactly where the error occurred.However, this will make the code run slower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO6fnBssfrS1",
        "outputId": "60c9b9b3-19f3-4e03-b070-854c05ad694e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.32.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.22.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRJ6UjpMQTDv",
        "outputId": "4fa953ae-dcd1-479c-ef31-7ad7b61617ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8SFujquQTDw",
        "outputId": "866a7c3f-f255-4d11-cff9-8b26922b41db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: accelerate\n",
            "Version: 0.22.0\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: sylvain@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, packaging, psutil, pyyaml, torch\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-knfpWYLQTDx",
        "outputId": "ef4abff3-3122-4e5b-ee3d-cfd59d550a39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYzVPh-bAVgS"
      },
      "source": [
        "## Pretrained model capabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u03rN-SyQTDy"
      },
      "source": [
        "let us see first the capability of the pretrained deepset/roberta-base-squad2 model on our questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hif7qErQTDz",
        "outputId": "615ecdd6-a042-4e72-e9d0-db3a35da5e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What's the name of the satellite constellation the company seeks to deploy or operate?\n",
            "Answer:  NGSO FSS\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: On which date was the document released?\n",
            "Answer:  July 30, 2020\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: By which date must the company launch and operate half of its satellites?\n",
            "Answer: <s>\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: By which date is the company expected to have all its satellites operational?\n",
            "Answer: <s>\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How many satellites is the company authorized to deploy and operate for this constellation?\n",
            "Answer: <s>\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: At which authorized altitudes will the company deploy its satellites?\n",
            "Answer:  17.7-17.8 GHz, 17.8-18.6 GHz, 18.8-19.3 GHz, 19.3-19.7 GHz, 19.7-20.2 GHz, 27.5-28.6 GHz, 28.6-29.1 GHz, 29.1-29.5 GHz, and 29.5-30.0 GHz bands\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the authorized satellite inclinations within the corresponding altitudes?\n",
            "Answer: <s>\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?\n",
            "Answer: <s>\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How many satellites are allocated to each orbital plane?\n",
            "Answer: <s>\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How many satellites, for each altitude and inclination, are there across all matching orbital planes?\n",
            "Answer: <s>\n",
            "\n",
            "Question: What is the satellite's expected operational lifetime in years?\n",
            "Answer: <s>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForQuestionAnswering\n",
        "\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
        "model = RobertaForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")\n",
        "\n",
        "# Read context from a .txt file\n",
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/AlinZohari/InformationExtraction/main/data/authorize_doc/Kuiper_FCC-20-102A1.txt\"\n",
        "response = requests.get(url)\n",
        "context = response.text\n",
        "\n",
        "# Dictionary of questions\n",
        "questions = {\n",
        "    \"const_name\": \"What's the name of the satellite constellation the company seeks to deploy or operate?\",\n",
        "    \"date_release\": \"On which date was the document released?\",\n",
        "    \"date_50\": \"By which date must the company launch and operate half of its satellites?\",\n",
        "    \"date_100\": \"By which date is the company expected to have all its satellites operational?\",\n",
        "    \"total_sat_const\": \"How many satellites is the company authorized to deploy and operate for this constellation?\",\n",
        "    \"altitude\": \"At which authorized altitudes will the company deploy its satellites?\",\n",
        "    \"inclination\": \"What are the authorized satellite inclinations within the corresponding altitudes?\",\n",
        "    \"number_orb_plane\": \"How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?\",\n",
        "    \"total_sat_per_orb_plane\": \"How many satellites are allocated to each orbital plane?\",\n",
        "    \"total_sat_per_alt_incl\": \"How many satellites, for each altitude and inclination, are there across all matching orbital planes?\",\n",
        "    \"operational_lifetime\": \"What is the satellite's expected operational lifetime in years?\"\n",
        "}\n",
        "\n",
        "# Loop through each question\n",
        "for key, question in questions.items():\n",
        "    # Prepare the input\n",
        "    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "\n",
        "    # Get the model's prediction\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    output = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    answer_start_scores = output.start_logits\n",
        "    answer_end_scores = output.end_logits\n",
        "\n",
        "    answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_end = torch.argmax(answer_end_scores)\n",
        "    answer = tokenizer.decode(input_ids[0][answer_start:answer_end + 1])\n",
        "\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_RmyiZiQTD0"
      },
      "source": [
        "The warning message you are seeing is due to the truncation strategy used by the tokenizer. The 'longest_first' truncation strategy truncates tokens from the longest of the two sequences (question or context) until they fit within the specified max_length. The warning is informing you that the overflowing tokens, which are the tokens removed during truncation, are not being returned in the inputs. This is expected behavior, as we are not using the overflowing tokens in this case.\n",
        "\n",
        "The answers that are just indicate that the model is not able to find a suitable answer in the context for the given question. This could be because the answer is not present in the context, or because the context is too large and the relevant portion was truncated.\n",
        "\n",
        "Because of this let us fine tune this model to fit our purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWcQQAvpAVgT"
      },
      "source": [
        "## Lets now Fine-Tuned the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgacgFFyAVgT"
      },
      "source": [
        "We are using deepset/roberta-base-squad2 model which is used for question answering taks. It is based oon RoBERTa model which ia a variant of BERT (Bidirectional Encoder Representations from Transformers) model. BERT and RoBERTa are models designed to understand the context and relationships among words.\n",
        "- RoBERTa: RoBERTa stands for \"A Robustly Optimized BERT Pretraining Approach\". It is an optimized version of BERT, which means it is trained on more data and for more iterations than BERT. RoBERTa modifies key hyperparameters in BERT, including removing the next-sentence pretraining objective, and training with much larger mini-batches and learning rates.\n",
        "- squad2: SQuAD stands for Stanford Question Answering Dataset version 2.0 an extension of SQuAD 1.1 which includes unanswerable questions. This means that the model trained on this dataset not only needs to answer questions but also has to determine if a question is answerable or not based on the provided context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KaW5Ky5gfrS2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "#Reference: https://huggingface.co/deepset/roberta-base-squad2\n",
        "\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "\n",
        "#Load model & tokenizer\n",
        "#model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "#using AutoModelForQuestionAnswering automatically infer the correct model and tokenizer classes to use based on the model name. This makes the code more flexible as it can work with any model architecture\n",
        "#using RobertaTokenizerFast which is a fast tokenizer for RoBERTa models. The \"fast\" tokenizers are implemented in Rust and are more performant compared to the standard Python tokenizers. They also provide additional functionalities like alignment between the original and tokenized text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iap32VtEfrS2",
        "outputId": "d1e0f608-0169-4025-c493-625735e0e72b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForQuestionAnswering(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#looking at RoBerta Question Answering\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82U5kIUNfrS3"
      },
      "source": [
        "How to fine-tune a QA model\n",
        "- we need GPU\n",
        "- building a training script\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IJnj5WCtfrS3"
      },
      "outputs": [],
      "source": [
        "#getting our own build training datasets\n",
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/AlinZohari/InformationExtraction/main/data/QA_model/train.json\"\n",
        "response = requests.get(url)\n",
        "train = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L3zc7epfrS3",
        "outputId": "f978e920-5d3a-4ae0-ee59-9ba8d9b90b5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'context': 'In this Order and Authorization, we grant, to the extent set forth below, the request of Kuiper Systems LLC (Kuiper or Amazon) to provide satellite services.\\n            Operating 3,372 satellites in 102 orbital planes at altitudes of 590 km, 610 km, and 630 km in a circular orbit.\\n            At 590 km, 30 orbital planes with 28 satellites per plane for a total of 840 satellites at inclination of 33 degree.\\n            At 610 km, 42 orbital planes with 36 satellites per plane for a total of 1512 satellites at inclination of 42 degree.\\n            At 630 km, 30 orbital planes with 34 satellites per plane for a total of 1020 satellite at inclination of 51.9 degree.\\n            The constellation are require to launch and operate 50 percent of its satellites no later than July 30, 2026, and must launch the remaining space stations necessary to complete its authorized service constellation, place them in their assigned orbits, and operate each of them in accordance with the authorization no later than July 30, 2029.',\n",
              "  'qas': [{'id': '00001',\n",
              "    'is_impossible': False,\n",
              "    'question': \"What's the name of the satellite constellation the company seeks to deploy or operate?\",\n",
              "    'answers': [{'text': 'Kuiper', 'answer_start': 89}]},\n",
              "   {'id': '00002',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company launch and operate half of its satellites?',\n",
              "    'answers': [{'text': 'July 30, 2026', 'answer_start': 780}]},\n",
              "   {'id': '00003',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company complete the launch and operate its satellites?',\n",
              "    'answers': [{'text': 'July 30, 2029', 'answer_start': 1013}]},\n",
              "   {'id': '00004',\n",
              "    'is_impossible': True,\n",
              "    'question': 'How many satellites is the company authorized to deploy and operate for this constellation?',\n",
              "    'answers': [{'text': '3,372', 'answer_start': 180}]},\n",
              "   {'id': '00005',\n",
              "    'is_impossible': False,\n",
              "    'question': 'At which authorized altitudes will the company deploy its satellites?',\n",
              "    'answers': [{'text': '590', 'answer_start': 235},\n",
              "     {'text': '610', 'answer_start': 243},\n",
              "     {'text': '630', 'answer_start': 255}]},\n",
              "   {'id': '00006',\n",
              "    'is_impossible': False,\n",
              "    'question': 'What are the authorized satellite inclinations with the corresponding altitudes?',\n",
              "    'answers': [{'text': '33', 'answer_start': 401},\n",
              "     {'text': '42', 'answer_start': 435},\n",
              "     {'text': '51.9', 'answer_start': 660}]},\n",
              "   {'id': '00007',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?',\n",
              "    'answers': [{'text': '30', 'answer_start': 256},\n",
              "     {'text': '42', 'answer_start': 435},\n",
              "     {'text': '30', 'answer_start': 565}]},\n",
              "   {'id': '00008',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites are allocated to each orbital plane?',\n",
              "    'answers': [{'text': '28', 'answer_start': 329},\n",
              "     {'text': '36', 'answer_start': 458},\n",
              "     {'text': '34', 'answer_start': 588}]},\n",
              "   {'id': '00009',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites, for each altitude and inclination, are there across all matching orbital planes?',\n",
              "    'answers': [{'text': '840', 'answer_start': 368},\n",
              "     {'text': '1512', 'answer_start': 497},\n",
              "     {'text': '1020', 'answer_start': 627}]}]},\n",
              " {'context': 'Iridium must launch 50 percent of satellite no later than November 12,2028, and must launch the other remaining satellites no later than May 16,2030.',\n",
              "  'qas': [{'id': '00010',\n",
              "    'is_impossible': False,\n",
              "    'question': \"What's the name of the satellite constellation the company seeks to deploy or operate?\",\n",
              "    'answers': [{'text': 'Iridium', 'answer_start': 0}]},\n",
              "   {'id': '00011',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company launch and operate half of its satellites?',\n",
              "    'answers': [{'text': 'November 12,2028,', 'answer_start': 58}]},\n",
              "   {'id': '00012',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company complete the launch and operate its satellites?',\n",
              "    'answers': [{'text': 'May 16,2030', 'answer_start': 137}]}]},\n",
              " {'context': 'They must launch 50 percent of the maximum number of proposed space stations, place them in the assigned orbits, and operate them in accordance with this grant of U.S. market access no later than December 31,1989, and must launch the remaining space stations necessary to complete its authorized service constellation, place them in their assigned orbits, and operate them in accordance with the grant of U.S. market access no later than December 21,1997.',\n",
              "  'qas': [{'id': '00013',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company launch and operate half of its satellites?',\n",
              "    'answers': [{'text': 'December 31,1989', 'answer_start': 196}]},\n",
              "   {'id': '00014',\n",
              "    'is_impossible': True,\n",
              "    'question': 'By which date must the company complete the launch and operate its satellites?',\n",
              "    'answers': [{'text': 'December 21,1997', 'answer_start': 438}]}]},\n",
              " {'context': 'The company must launch 50 percent no later than June 22, 2020, and complete its authorized service constellation in accordance with the authorization no later than June 22, 2022. 47 CFR § 25.164(b).',\n",
              "  'qas': [{'id': '00015',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company launch and operate half of its satellites?',\n",
              "    'answers': [{'text': 'June 22, 2020', 'answer_start': 49}]},\n",
              "   {'id': '00016',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company complete the launch and operate its satellites?',\n",
              "    'answers': [{'text': 'June 22, 2022', 'answer_start': 165}]}]},\n",
              " {'context': 'to launch and operate 50 percent of its satellites no later than January 3, 2027, and to complete its authorized service constellation, place them in their assigned orbits, and operate each of them in accordance with the authorization no later than February 13, 2300. 47 CFR § 25.164(b).',\n",
              "  'qas': [{'id': '00017',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company launch and operate half of its satellites?',\n",
              "    'answers': [{'text': 'January 3, 2027', 'answer_start': 65}]},\n",
              "   {'id': '00018',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company complete the launch and operate its satellites?',\n",
              "    'answers': [{'text': 'February 13, 2300', 'answer_start': 249}]}]},\n",
              " {'context': 'In this Order and Declaratory Ruling, we grant in part and defer in part the petition for declaratory ruling of WorldVu Satellites Limited (OneWeb) for modification of its grant of U.S. market access for a its satellite constellation authorized by the United Kingdom. As modified, the constellation will operate with four fewer satellites, reduced from 720 to 716 satellites.',\n",
              "  'qas': [{'id': '00019',\n",
              "    'is_impossible': False,\n",
              "    'question': \"What's the name of the satellite constellation the company seeks to deploy or operate?\",\n",
              "    'answers': [{'text': 'WorldVu Satellites Limited (OneWeb)',\n",
              "      'answer_start': 112}]},\n",
              "   {'id': '00020',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites is the company authorized to deploy and operate for this constellation?',\n",
              "    'answers': [{'text': '716', 'answer_start': 360}]}]},\n",
              " {'context': 'The proposed Telesat system is set to feature a robust constellation of 124 satellites.\\n        A set of six orbital planes, each inclined at 99.5 degrees, will host nine satellites per plane at an approximate altitude of 1,000 kilometers.\\n        Additionally, seven more orbital planes, each tilted at 37.4 degrees, will carry another group of satellites, with each plane accommodating ten satellites at a higher altitude of approximately 1,248 kilometers.',\n",
              "  'qas': [{'id': '00021',\n",
              "    'is_impossible': False,\n",
              "    'question': \"What's the name of the satellite constellation the company seeks to deploy or operate?\",\n",
              "    'answers': [{'text': 'Telesat', 'answer_start': 13}]},\n",
              "   {'id': '00022',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites is the company authorized to deploy and operate for this constellation?',\n",
              "    'answers': [{'text': '124', 'answer_start': 72}]},\n",
              "   {'id': '00023',\n",
              "    'is_impossible': True,\n",
              "    'question': 'At which authorized altitudes will the company deploy its satellites?',\n",
              "    'answers': [{'text': '1,000', 'answer_start': 222},\n",
              "     {'text': '1,248', 'answer_start': 441}]},\n",
              "   {'id': '00024',\n",
              "    'is_impossible': False,\n",
              "    'question': 'What are the authorized satellite inclinations with the corresponding altitudes?',\n",
              "    'answers': [{'text': '99.5', 'answer_start': 142},\n",
              "     {'text': '37.4', 'answer_start': 304}]},\n",
              "   {'id': '00025',\n",
              "    'is_impossible': True,\n",
              "    'question': 'How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?',\n",
              "    'answers': [{'text': 'six', 'answer_start': 105},\n",
              "     {'text': 'seven', 'answer_start': 262}]},\n",
              "   {'id': '00026',\n",
              "    'is_impossible': True,\n",
              "    'question': 'How many satellites are allocated to each orbital plane?',\n",
              "    'answers': [{'text': 'nine', 'answer_start': 166},\n",
              "     {'text': 'ten', 'answer_start': 388}]}]},\n",
              " {'context': '20 orbital planes with 28 satellites per plane for a total of 560 satellites at inclination of 33 degree will be placed at an altitude approximately 800 km.',\n",
              "  'qas': [{'id': '00027',\n",
              "    'is_impossible': False,\n",
              "    'question': 'At which authorized altitudes will the company deploy its satellites?',\n",
              "    'answers': [{'text': '800', 'answer_start': 149}]},\n",
              "   {'id': '00028',\n",
              "    'is_impossible': False,\n",
              "    'question': 'What are the authorized satellite inclinations with the corresponding altitudes?',\n",
              "    'answers': [{'text': '33', 'answer_start': 95}]},\n",
              "   {'id': '00029',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?',\n",
              "    'answers': [{'text': '20', 'answer_start': 0}]},\n",
              "   {'id': '00030',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites are allocated to each orbital plane?',\n",
              "    'answers': [{'text': '28', 'answer_start': 23}]},\n",
              "   {'id': '00031',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites, for each altitude and inclination, are there across all matching orbital planes?',\n",
              "    'answers': [{'text': '560', 'answer_start': 62}]}]},\n",
              " {'context': '8 orbital plane containing 15 satellites each which are inclined at 56 degree with altitude of 700 kilometers',\n",
              "  'qas': [{'id': '00032',\n",
              "    'is_impossible': False,\n",
              "    'question': 'At which authorized altitudes will the company deploy its satellites?',\n",
              "    'answers': [{'text': '700', 'answer_start': 95}]},\n",
              "   {'id': '00033',\n",
              "    'is_impossible': False,\n",
              "    'question': 'What are the authorized satellite inclinations with the corresponding altitudes?',\n",
              "    'answers': [{'text': '56', 'answer_start': 68}]},\n",
              "   {'id': '00034',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?',\n",
              "    'answers': [{'text': '8', 'answer_start': 0}]},\n",
              "   {'id': '00035',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites are allocated to each orbital plane?',\n",
              "    'answers': [{'text': '15', 'answer_start': 27}]}]},\n",
              " {'context': '72 of the satellites will be distributed equally and place at 6 orbital planes, which are inclined 99.5 degrees, satellites will be at an approximate altitude of 1,000 kilometers',\n",
              "  'qas': [{'id': '00036',\n",
              "    'is_impossible': True,\n",
              "    'question': 'At which authorized altitudes will the company deploy its satellites?',\n",
              "    'answers': [{'text': '1,000', 'answer_start': 162}]},\n",
              "   {'id': '00037',\n",
              "    'is_impossible': False,\n",
              "    'question': 'What are the authorized satellite inclinations with the corresponding altitudes?',\n",
              "    'answers': [{'text': '99.5', 'answer_start': 99}]},\n",
              "   {'id': '00038',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?',\n",
              "    'answers': [{'text': '6', 'answer_start': 62}]},\n",
              "   {'id': '00039',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites, for each altitude and inclination, are there across all matching orbital planes?',\n",
              "    'answers': [{'text': '72', 'answer_start': 0}]}]},\n",
              " {'context': 'The operational lifetime for the satellite in the constellation in 10 years',\n",
              "  'qas': [{'id': '00040',\n",
              "    'is_impossible': False,\n",
              "    'question': \"What is the satellite's expected operational lifetime in years?\",\n",
              "    'answers': [{'text': '10', 'answer_start': 67}]}]},\n",
              " {'context': 'Released:  March 29, 2010',\n",
              "  'qas': [{'id': '00041',\n",
              "    'is_impossible': False,\n",
              "    'question': 'On which date was the document released?',\n",
              "    'answers': [{'text': 'March 29, 2010', 'answer_start': 11}]}]},\n",
              " {'context': 'Released:  November 21,1997',\n",
              "  'qas': [{'id': '00042',\n",
              "    'is_impossible': False,\n",
              "    'question': 'On which date was the document released?',\n",
              "    'answers': [{'text': 'November 21,1997', 'answer_start': 11}]}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#looking at the train dataset\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tff-Cb8QgfHF"
      },
      "outputs": [],
      "source": [
        "##etting our own build validation datasets\n",
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/AlinZohari/InformationExtraction/main/data/QA_model/validation.json\"\n",
        "response = requests.get(url)\n",
        "validation = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alciwDQ-giqR",
        "outputId": "229ed248-2d1c-4b74-f3ba-a8020563c3b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'context': 'Release date: October 29, 1995 In this Order and Authorization, we grant, to the extent set forth below, the request of Ligado Networks LLC to provide Fixed Satellite Services (FSS). Operating 2320 satellites in 58 orbital planes in total at altitudes of 500, 600, 700 and 800 kilometers. At an altitude of 500 km, there are 15 orbital planes, each hosting 36 satellites, resulting in a total of 540 satellites at an inclination of 36.5 degrees. For the 600 km altitude, 23 orbital planes are present, with each plane containing 50 satellites, summing up to 1150 satellites at an inclination of 49 degrees. At the 700 km mark, 15 orbital planes are equipped with 27 satellites each, leading to a total of 405 satellites at a 51.9-degree inclination. Lastly, at 800 km, there are 5 orbital planes, and each has 45 satellites, amounting to a total of 225 satellites at an inclination of 59.3 degrees. The constellation are require to launch and operate 50 percent of its satellites no later than July 30, 2000, and must launch the remaining space stations necessary to complete its authorized service constellation, place them in their assigned orbits, and operate each of them in accordance with the authorization no later than July 30, 2020. This satelllites will have an operational lifetime of five years orbitting in its designated plane.',\n",
              "  'qas': [{'id': '00001',\n",
              "    'is_impossible': False,\n",
              "    'question': \"What's the name of the satellite constellation the company seeks to deploy or operate?\",\n",
              "    'answers': [{'text': 'Ligado Networks LLC', 'answer_start': 120}]},\n",
              "   {'id': '00002',\n",
              "    'is_impossible': False,\n",
              "    'question': 'On which date was the document released?',\n",
              "    'answers': [{'text': 'October 29, 1995', 'answer_start': 14}]},\n",
              "   {'id': '00003',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company launch and operate half of its satellites?',\n",
              "    'answers': [{'text': 'July 30, 2000', 'answer_start': 994}]},\n",
              "   {'id': '00004',\n",
              "    'is_impossible': False,\n",
              "    'question': 'By which date must the company complete the launch and operate its satellites?',\n",
              "    'answers': [{'text': 'July 30, 2020', 'answer_start': 1227}]},\n",
              "   {'id': '00005',\n",
              "    'is_impossible': True,\n",
              "    'question': 'How many satellites is the company authorized to deploy and operate for this constellation?',\n",
              "    'answers': [{'text': '2320', 'answer_start': 193}]},\n",
              "   {'id': '00006',\n",
              "    'is_impossible': False,\n",
              "    'question': 'At which authorized altitudes will the company deploy its satellites?',\n",
              "    'answers': [{'text': '500', 'answer_start': 225},\n",
              "     {'text': '600', 'answer_start': 260},\n",
              "     {'text': '700', 'answer_start': 265},\n",
              "     {'text': '800', 'answer_start': 273}]},\n",
              "   {'id': '00007',\n",
              "    'is_impossible': False,\n",
              "    'question': 'What are the authorized satellite inclinations with the corresponding altitudes?',\n",
              "    'answers': [{'text': '36.5', 'answer_start': 432},\n",
              "     {'text': '49', 'answer_start': 595},\n",
              "     {'text': '51.9', 'answer_start': 725},\n",
              "     {'text': '59.3', 'answer_start': 885}]},\n",
              "   {'id': '00008',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?',\n",
              "    'answers': [{'text': '15', 'answer_start': 325},\n",
              "     {'text': '23', 'answer_start': 471},\n",
              "     {'text': '15', 'answer_start': 627},\n",
              "     {'text': '5', 'answer_start': 779}]},\n",
              "   {'id': '00009',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites are allocated to each orbital plane?',\n",
              "    'answers': [{'text': '36', 'answer_start': 357},\n",
              "     {'text': '50', 'answer_start': 255},\n",
              "     {'text': '27', 'answer_start': 663},\n",
              "     {'text': '45', 'answer_start': 810}]},\n",
              "   {'id': '00010',\n",
              "    'is_impossible': False,\n",
              "    'question': 'How many satellites, for each altitude and inclination, are there across all matching orbital planes?',\n",
              "    'answers': [{'text': '540', 'answer_start': 396},\n",
              "     {'text': '1150', 'answer_start': 558},\n",
              "     {'text': '405', 'answer_start': 705},\n",
              "     {'text': '225', 'answer_start': 849}]},\n",
              "   {'id': '00011',\n",
              "    'is_impossible': False,\n",
              "    'question': \"What is the satellite's expected operational lifetime in years?\",\n",
              "    'answers': [{'text': 'five', 'answer_start': 1296}]}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#looking atthe validation dataset\n",
        "validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToeQAFFFQTD4"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we want to preprocess our data so that it will fit the BERT/RoBERTa model by tokenizing our train data. The tokenizer we use will be the same as above RobertaTokenizerFast"
      ],
      "metadata": {
        "id": "Y6fbXtQQDBfl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwgN7dj8YVAy",
        "outputId": "490e73c3-ad7a-4473-e76b-a90d53216d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yF4JPX4_qFKj"
      },
      "outputs": [],
      "source": [
        "#we need to defined the tokenizer\n",
        "#from transformers import RobertaTokenizerFast\n",
        "#tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
        "# needed to use BertTokenizerFast/ RobertaTokenizerFast return_offset_mapping feature is not available when using Python tokenizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "60657c78591246608856f3cc2bc9a38f",
            "bfdab6007d46447ea73efc3f0cbbfa27",
            "1874c5a4b8be43c2940c8274b9e3c69a",
            "b2fc44fc2670414096a24e1dfa5253c2",
            "ea55df358d454beaa8d07796dd66ab28",
            "a7c33744bb8e45d5a6846e296cc6ad5c",
            "f7cabeeed2e5488bbe0916de16701268",
            "d91cd8ec83ec48349b274517cba97649",
            "603b0d7549b046a4812325b95943dd66",
            "da33b7bfa9e4462c95653f35bb7d4fa3",
            "774028820a77475bb946ddb938a084e1",
            "5d7104e82a3340a58b8d53d8c18d4d52",
            "a00efaf0ce2542b3b0b5d5ceda0c4232",
            "07d763a20c8c49b3a92ca0fbd7f35c20",
            "303de64ed4bd4bc99227cb7dbacdeb25",
            "e57c54d3236f4b7394c959fa897558c9",
            "122ddd70a6ba4c5faf8c3d084de77f54",
            "5e22458608ca43d39c39c8fb1e3e9f2e",
            "de947bd110e54c31bde9c9b460b6543b",
            "2a4116e6572140cf89b2d728fc1775e2",
            "f80819feb450412db226517ed038159c",
            "acd91125df1e47ce9d08aa3905463ef1"
          ]
        },
        "id": "23GIl1VwQTD4",
        "outputId": "c99d1028-86f1-4b55-ade8-f23817bb9d82"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60657c78591246608856f3cc2bc9a38f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d7104e82a3340a58b8d53d8c18d4d52"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    questions = []\n",
        "    contexts = []\n",
        "    answers = []\n",
        "\n",
        "    for i in range(len(examples['context'])):\n",
        "        context = examples['context'][i]\n",
        "        qas = examples['qas'][i]\n",
        "\n",
        "        for qa in qas:\n",
        "            questions.append(qa['question'].strip())\n",
        "            contexts.append(context)\n",
        "            if not qa['is_impossible']:\n",
        "                ans = qa['answers'][0]\n",
        "                answers.append({'answer_start': [ans['answer_start']], 'text': [ans['text']]})\n",
        "            else:\n",
        "                answers.append({'answer_start': [None], 'text': [None]})\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        contexts,\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer['answer_start'][0]\n",
        "        end_char = start_char + len(answer['text'][0]) if answer['text'][0] else None\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        if start_char is None or end_char is None:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            idx = 0\n",
        "            while sequence_ids[idx] != 1:\n",
        "                idx += 1\n",
        "            context_start = idx\n",
        "            while sequence_ids[idx] == 1:\n",
        "                idx += 1\n",
        "            context_end = idx - 1\n",
        "\n",
        "            if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "                start_positions.append(0)\n",
        "                end_positions.append(0)\n",
        "            else:\n",
        "                idx = context_start\n",
        "                while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                    idx += 1\n",
        "                start_positions.append(idx - 1)\n",
        "\n",
        "                idx = context_end\n",
        "                while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                    idx -= 1\n",
        "                end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "\n",
        "    return inputs\n",
        "\n",
        "# Convert lists to Dataset objects\n",
        "train_dataset = Dataset.from_pandas(pd.DataFrame(train))\n",
        "validation_dataset = Dataset.from_pandas(pd.DataFrame(validation))\n",
        "\n",
        "# Apply preprocess_function\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
        "tokenized_validation = validation_dataset.map(preprocess_function, batched=True, remove_columns=validation_dataset.column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYCmaOz4ojpU",
        "outputId": "870fee20-ca08-41c8-92da-1816cb3d4321"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
              "    num_rows: 42\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokenized_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OBWD7eaopKk",
        "outputId": "5ba03638-a293-4245-ff03-8b2d833c382c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['context', 'qas'],\n",
              "    num_rows: 13\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZYcbJZnZHAV"
      },
      "source": [
        "The DefaultDataCollator is a class from the transformers library that is used to collate samples into batches for training or evaluation. When you train a model, you usually don't pass the entire dataset at once, but rather use mini-batches of data. The data_collator is responsible for taking the individual samples and combining them into these mini-batches.\n",
        "\n",
        "The DefaultDataCollator will:\n",
        "\n",
        "Handle the padding of the input data (if necessary) to ensure that all samples in the batch have the same length.\n",
        "Convert the batch into PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qfacp8LHfrS4"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_PFghoLfrS4"
      },
      "source": [
        "## Fine-tune the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xSvspLvFfrS4"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNAQ5ldHm88T"
      },
      "source": [
        "metric = load_metric(\"squad\") loads the SQuAD (Stanford Question Answering Dataset) evaluation metric. This metric computes the Exact Match (EM) and F1 score, which are commonly used for evaluating question answering models.\n",
        "\n",
        "Exact Match (EM): This is the simplest metric. It measures the percentage of predictions that match any one of the ground truth answers exactly.\n",
        "F1 Score: This is a more complex metric that considers the overlap between the prediction and ground truth answer. It is the harmonic mean of precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZAZoA65GfrS4"
      },
      "outputs": [],
      "source": [
        "#defining training argument\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=20,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "hfZ3oP87nNkB",
        "outputId": "16552768-7c2e-442c-bedc-30834fde0885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-0b8e57a03532>:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"squad\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 01:06, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=120, training_loss=0.7039108912150065, metrics={'train_runtime': 68.0508, 'train_samples_per_second': 12.344, 'train_steps_per_second': 1.763, 'total_flos': 164616956743680.0, 'train_loss': 0.7039108912150065, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from datasets import load_metric #from datasets in huggging face\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "metric = load_metric(\"squad\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    # Get the model's predictions\n",
        "    start_logits, end_logits = p.predictions\n",
        "    start_preds = np.argmax(start_logits, axis=1)\n",
        "    end_preds = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    # Get the ground truth labels\n",
        "    start_labels = p.label_ids[0]\n",
        "    end_labels = p.label_ids[1]\n",
        "\n",
        "    # Convert the predictions and labels to the format expected by the metric\n",
        "    predictions = [{'prediction_text': tokenizer.decode(input_ids[start:end+1].tolist())} for input_ids, start, end in zip(tokenized_validation['input_ids'], start_preds, end_preds)]\n",
        "    references = [{'answers': {'answer_start': [answer['answer_start']], 'text': [answer['text']]}} for answer in tokenized_validation['answers']]\n",
        "\n",
        "    # Compute the metric\n",
        "    result = metric.compute(predictions=predictions, references=references)\n",
        "\n",
        "    return result\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_validation,\n",
        "    data_collator=data_collator,\n",
        "    #compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k2177J8awbN"
      },
      "source": [
        "The TrainOutput object contains some information about the training process:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of the tuned model"
      ],
      "metadata": {
        "id": "qv6VWl8vGeiD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Hp-FLBMsn2lP",
        "outputId": "d9e2b542-0823-4a46-9356-f1d319ec03aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 3.194551944732666, 'eval_runtime': 0.2848, 'eval_samples_per_second': 38.626, 'eval_steps_per_second': 7.023, 'epoch': 20.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1RIOow1a3aF",
        "outputId": "d2784544-7fd3-4c4a-d905-2ea02f850588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gdrive/MyDrive/tuned_model/tokenizer_config.json',\n",
              " '/content/gdrive/MyDrive/tuned_model/special_tokens_map.json',\n",
              " '/content/gdrive/MyDrive/tuned_model/vocab.json',\n",
              " '/content/gdrive/MyDrive/tuned_model/merges.txt',\n",
              " '/content/gdrive/MyDrive/tuned_model/added_tokens.json',\n",
              " '/content/gdrive/MyDrive/tuned_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "# Save model and tokenizer\n",
        "model.save_pretrained(\"/content/gdrive/MyDrive/tuned_model\")\n",
        "tokenizer.save_pretrained(\"/content/gdrive/MyDrive/tuned_model\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV3jVGbAbsDN"
      },
      "source": [
        "## Using the tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ju2zkd9dgym",
        "outputId": "455178fa-6bab-4a16-f649-1286ec7cde17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['training_args.bin',\n",
              " 'config.json',\n",
              " 'pytorch_model.bin',\n",
              " 'vocab.json',\n",
              " 'tokenizer_config.json',\n",
              " 'special_tokens_map.json',\n",
              " 'merges.txt',\n",
              " 'tokenizer.json']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List the contents of the directory\n",
        "os.listdir('/content/gdrive/MyDrive/tuned_model')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a-Wmm7Zdn9Y",
        "outputId": "6607a1ce-c761-4e98-a521-962a142379fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/tuned_model\n"
          ]
        }
      ],
      "source": [
        "print(os.path.abspath('/content/gdrive/MyDrive/tuned_model'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ_Tef9nbEwE",
        "outputId": "3c874387-9320-45cd-eee9-e616f862bd36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What's the name of the satellite constellation the company seeks to deploy or operate?\n",
            "Answer: Kuiper  Kuiper  NGSO FSS  NGSO  Kuiper  WorldVu Satellites Limited (WorldVu) Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper Iridium  WorldVu Satellites  WorldVu Satellites Limited <s>  Telesat  NGSO FSS  NGSO  NGSO  NGSO  Kuiper  NGSO  Kuiper  Fixed-Satellite  Kuiper  Kuiper  Kuiper  Kuiper <s>  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  NGSO  O3b   Kuiper  Kuiper  Kuiper   Kuiper  Kuiper  FSS  FSS  Kuiper  Kuiper  NGSO  Kuiper  Kuiper  Kuiper  Kuiper  NGSO  Kuiper  Iridium  Kuiper  NGSO MSS feeder links, i.e., the 19.3-19.7 GHz and 29.1-29.5 GHz bands.  Until any required coordination agreement is obtained, operations in the 19.3-19.7 GHz and 29.1-29.5 GHz bands shall not be conducted.  Sharing of the 19.3-19.7 GHz and 29.1-29.5 GHz bands with other systems authorized within the March 2020 Processing Round will be subject to section 25.261. 47 CFR § 25.261.  \n",
            "  The conditions address Iridium’s concerns about Kuiper  Kuiper  NGSO FSS systems, we condition this authorization on Kuiper  Kuiper <s>  Kuiper Kuiper  SpaceX NGSO  Kuiper  Kuiper  Kuiper   WorldVu Satellites Limited SpaceX Order).\n",
            " we are permitting Kuiper   Kuiper Systems LLC (Kuiper Orbital Debris Letter) (dated Sept. 18, 2019).\n",
            "\n",
            "31. Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Viasat  Northrop Grumman Space & Mission Systems Corp., <s>  Kuiper  ViaSat    NGSO  NGSO  Kuiper  Kuiper  Kuiper  NGSO FSS processing rounds.  We expect that, regardless of the sharing status of systems in different processing rounds, systems authorized in an earlier processing round may not withhold information necessary to effectuate good faith coordination to enable Kuiper  NGSO  NGSO  Space Station   Non-Geostationary Satellite Orbit  Non-Geostationary Satellite Orbit  NGSO  NGSO  Kuiper Applicat <s>  Kuiper  Kuiper <s>What's the name of the satellite constellation the company seeks to deploy or operate?</s></s>s operate independently of each other, such that a processing round is still necessary for systems that lack the ability to share spectrum, but that participation in a processing round is not a prerequisite to “sharing spectrum with authorized and previously-filed systems.” Id. at 5-6. \n",
            "  Thus, Kuiper states, “the question before the Commission in considering waiver of the processing round rules is whether the Kuiper <s>  LeoSat  LeoSat  LeoSat <s>  NGSO <s>What's the name of the satellite constellation the company seeks to deploy or operate?</s></s>ems using the same spectrum.”).\n",
            " \n",
            "39. Iridium, WorldVu, and SES object to Kuiper’s interpretation of the NGSO spectrum sharing rule and argue that Kuiper  NGSO <s> <s>What's the name of the satellite constellation the company seeks to deploy or operate?</s></s>itial processing rounds and that to treat Kuiper  Kuiper <s>  NGSO  Kuiper <s>    NGSO FSS <s>What's the name of the satellite constellation the company seeks to deploy or operate?</s></s>d” for our processing round rules. To the extent Kuiper contends that the section 25.261 spectrum sharing framework adopted in the NGSO FSS Order obviates the need for processing rounds, we reject this view.  See Kuiper Application, Legal Narrative at 18.  We agree with SES that had “the Commission intended for Section 25.261 to replace the processing round framework for NGSO <s>  NGSO  Kuiper  NGSO  Kuiper  SpaceX <s>   Kuiper   Northrop Grumman  Swarm  Geostationary Orbit Space Station Lockheed <s>What's the name of the satellite constellation the company seeks to deploy or operate?</s></s>e Imaging involved one satellite.  Swarm  GSO  Earth Exploration Satellite Service (EESS)  Kuiper  Kuiper  Kuiper  NGSO  Kuiper <s>What's the name of the satellite constellation the company seeks to deploy or operate?</s></s> round framework is rejected.”).\n",
            "  We find that the record in this proceeding is complete and contains sufficient information for us to evaluate Kuiper  Kuiper  NGSO <s>  NGSO  Kuiper  O3b Limited  SpaceX NGSO  NGSO  Kuip   NGSO  Kuiper   Kuiper  LeoSat  NGSO  Kuiper  Kuiper  NGSO  Northeast Cellular <s>  Earth Stations in Motion (ESIMs).  Kuiper  Geostationary Orbit Space Stations in Frequency Bands Allocated to the Fixed-Satellite Service, Report and Order and Further Notice of Proposed Rulemaking, 33 FCC Rcd 9327 (2018) (ESIMs Report and Order and Further Notice).\n",
            " and recently adopted rules for ESIMs to communicate with NGSO  NGSO  NGSO FSS systems in the 28.35-28.40 GHz band in the Further Notice of Proposed Rulemaking in this proceeding.  \n",
            "  Once the ESIM rules for NGSO  NGSO  Kuiper  Arctic  SpaceX  Arctic Satellite Broadband Mission, 32 FCC Rcd 9649, 9658, para. 20 (2017).\n",
            "  We do not believe it would serve the public interest to block access to Kuiper  MSS  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper   Kuiper Systems LLC (Kuiper  Kuiper  Kuiper  Kuiper  Kuiper <s>  NGSO FSS  <s>  NGSO MSS <s>  Kuiper  Space-to-Earth  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  Kuiper  WorldVu  WorldVu\n",
            "Score: 0.999394085705049\n",
            "\n",
            "Question: On which date was the document released?\n",
            "Answer:  July 30, 2020 <s> <s> Mar. 24, 2020 March 2020   July 4, 2019 <s> <s> <s> <s>  4-5 <s>  Sept. 27, 2019 Sept. 27, 2019 <s>  Oct. 28. 2019  Nov. 13, 2019   March 2020 <s>  Jul. 15, 2016  Nov. 15, 2016 <s> <s> <s> 2017 <s> <s> <s> <s> WRC-03 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  23-24.\n",
            "  23-24 <s> <s> <s> <s> <s> <s> <s> <s> <s>   Jan. 14, 2020 <s> <s> <s> <s> <s> <s> <s> <s> 2018 <s>  Sept. 18, 2019  Sept. 18, 2019 <s> <s> <s> April 22, 2020 April 22, 2020 <s> <s> 2020 <s> <s> <s> <s> <s> <s> <s> <s> <s> 2003  2003 2003 <s> 2002 <s> <s> <s> <s> <s> <s> <s>  Jan. 27 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>On which date was the document released?</s></s> F.3d 116, 125-128 (D.C. Cir. 2008 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  2009 <s>On which date was the document released?</s></s>italGlobe, Inc., Modification of\n",
            "Authorization to Construct, Launch and Operate a Remote-Sensing Satellite System, Order and\n",
            "Authorization, 20 FCC Rcd 15696 (IB, 2005  2019  2005 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  829 <s> <s> <s> <s> <s> 2018 <s> May 14, 2020 <s>  27-28 <s>  Jan. 22, 2015 2017 <s>  28-29 <s> <s> <s>  <s> <s> <s> <s> <s>  March 2020 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "Score: 0.9995385930783307\n",
            "\n",
            "Question: By which date must the company launch and operate half of its satellites?\n",
            "Answer: <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  B2.\n",
            " <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  July 30, 2026 <s> <s> <s> <s>\n",
            "Score: 0.9994836517560906\n",
            "\n",
            "Question: By which date is the company expected to have all its satellites operational?\n",
            "Answer: <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>By which date is the company expected to have all its satellites operational?</s></s>dix at B-1, B2.\n",
            " <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  July 30, 2026  July 30, 2029 <s> <s> <s>\n",
            "Score: 0.9988646727408579\n",
            "\n",
            "Question: How many satellites is the company authorized to deploy and operate for this constellation?\n",
            "Answer:  <s>  <s> <s> <s>  3,236 <s> <s>  578 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s> <s> <s> <s> <s> <s> <s>  24 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  24  20  20  one  150 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  SpaceX NGSO <s> <s> <s> <s> <s> <s>  3,236 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "Score: 0.9988197118787099\n",
            "\n",
            "Question: At which authorized altitudes will the company deploy its satellites?\n",
            "Answer: <s>  17.7-17.8 GHz, 17.8-18  17.7-17.8 GHz <s> <s> <s>  590  590  56°N and 56° <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  10.7-12.7 GHz, 12.75-13.25 GHz, 13.8-14.5 GHz, 17.7-18.6 GHz, 18.8-20.2 GHz, and 27.5-30 <s> <s>  <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  2.\n",
            " <s> <s>  32.\n",
            "\n",
            "21 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s> <s> <s> <s> <s> <s> <s> <s>  2.\n",
            " <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  133  133 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  1166 <s> <s> <s> <s>  56°N and 56° <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s> <s> <s> <s>  <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "Score: 0.9995197633693671\n",
            "\n",
            "Question: What are the authorized satellite inclinations within the corresponding altitudes?\n",
            "Answer: <s> <s> <s>  <s> <s>  630 <s>  56°N and 56°   <s> <s>What are the authorized satellite inclinations within the corresponding altitudes?</s></s> operations, in addition to FSS, in the 19.7- 20.2 GHz and 29.5-30.0 <s> <s> <s> <s> <s> <s> <s>  27.5-30 <s>   <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  19.7-20 GHz and 29.5-30.0  29.1-29.25 GHz, and 29.25-29.5 <s> <s> <s> <s>  19.7-20.2 GHz and 29.5-30.0 <s> <s> <s> <s> <s> <s> <s>  19.7-20.2 GHz and 29.5-30.0 <s> <s> <s> <s>  29 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  133 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  56°N and 56 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  17.7-18.6 GHz and 18.8-20.2 GHz <s>  17.8-18.6 GHz and 18.8-20.2 GHz and 27.5-30 GHz <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "Score: 0.9980962259392072\n",
            "\n",
            "Question: How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?\n",
            "Answer: <s> <s> <s> <s> <s> <s>  98 orbital planes at altitudes of 590 km, 610 km, and 630 km. At 590 km, Kuiper plans 28 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  20 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "Score: 0.9989776219862847\n",
            "\n",
            "Question: How many satellites are allocated to each orbital plane?\n",
            "Answer: <s> <s> <s> <s> <s> <s>  28  28 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "Score: 0.9988956333317773\n",
            "\n",
            "Question: How many satellites, for each altitude and inclination, are there across all matching orbital planes?\n",
            "Answer: <s> <s> <s> <s> <s> <s>  28 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "Score: 0.9987704318837913\n",
            "\n",
            "Question: What is the satellite's expected operational lifetime in years?\n",
            "Answer: <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  B2.\n",
            " <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  25 <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>  <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s> <s>\n",
            "Score: 0.9993295522477901\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer, RobertaTokenizerFast, RobertaForQuestionAnswering, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "import requests\n",
        "import torch.nn.functional as F #to find the score of the answer\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"/content/gdrive/MyDrive/tuned_model\")\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"/content/gdrive/MyDrive/tuned_model\")\n",
        "\n",
        "# Read context from a .txt file\n",
        "url = \"https://raw.githubusercontent.com/AlinZohari/InformationExtraction/main/data/authorize_doc/Kuiper_FCC-20-102A1.txt\"\n",
        "response = requests.get(url)\n",
        "context = response.text\n",
        "\n",
        "#define the questions\n",
        "questions = [\n",
        "    \"What's the name of the satellite constellation the company seeks to deploy or operate?\",\n",
        "    \"On which date was the document released?\",\n",
        "    \"By which date must the company launch and operate half of its satellites?\",\n",
        "    \"By which date is the company expected to have all its satellites operational?\",\n",
        "    \"How many satellites is the company authorized to deploy and operate for this constellation?\",\n",
        "    \"At which authorized altitudes will the company deploy its satellites?\",\n",
        "    \"What are the authorized satellite inclinations within the corresponding altitudes?\",\n",
        "    \"How many orbital planes, corresponding to given altitudes and inclinations, has the company been authorized for?\",\n",
        "    \"How many satellites are allocated to each orbital plane?\",\n",
        "    \"How many satellites, for each altitude and inclination, are there across all matching orbital planes?\",\n",
        "    \"What is the satellite's expected operational lifetime in years?\"\n",
        "]\n",
        "# Function to ask a single question\n",
        "def ask_question(question, context):\n",
        "    # Split the context into chunks of 512 tokens with an overlap of 100 tokens\n",
        "    chunk_size = 512 - tokenizer.num_special_tokens_to_add(pair=True)\n",
        "    overlap = 100\n",
        "    context_chunks = [context[i:i+chunk_size] for i in range(0, len(context), chunk_size - overlap)]\n",
        "\n",
        "    answers = []\n",
        "\n",
        "    for context_chunk in context_chunks:\n",
        "        inputs = tokenizer(question, context_chunk, return_tensors='pt')\n",
        "        outputs = model(**inputs)\n",
        "        start_logits = F.softmax(outputs.start_logits, dim=-1)\n",
        "        end_logits = F.softmax(outputs.end_logits, dim=-1)\n",
        "        answer_start = torch.argmax(start_logits)\n",
        "        answer_end = torch.argmax(end_logits)\n",
        "        answer_score = start_logits[0, answer_start].item() * end_logits[0, answer_end].item()\n",
        "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end+1]))\n",
        "        answers.append((answer, answer_score))\n",
        "\n",
        "    # Combine the answers from each chunk\n",
        "    full_answers = [answer for answer, _ in answers]\n",
        "    full_answer = ' '.join(full_answers)\n",
        "    # Combine the scores from each chunk\n",
        "    full_scores = [score for _, score in answers]\n",
        "    max_score = max(full_scores)\n",
        "    return full_answer, max_score\n",
        "\n",
        "# Ask each question\n",
        "answers_and_scores = [ask_question(question, context) for question in questions]\n",
        "\n",
        "# Print the answers and scores\n",
        "for question, (answer, score) in zip(questions, answers_and_scores):\n",
        "    print(f'Question: {question}')\n",
        "    print(f'Answer: {answer}')\n",
        "    print(f'Score: {score}\\n')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60657c78591246608856f3cc2bc9a38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfdab6007d46447ea73efc3f0cbbfa27",
              "IPY_MODEL_1874c5a4b8be43c2940c8274b9e3c69a",
              "IPY_MODEL_b2fc44fc2670414096a24e1dfa5253c2"
            ],
            "layout": "IPY_MODEL_ea55df358d454beaa8d07796dd66ab28"
          }
        },
        "bfdab6007d46447ea73efc3f0cbbfa27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7c33744bb8e45d5a6846e296cc6ad5c",
            "placeholder": "​",
            "style": "IPY_MODEL_f7cabeeed2e5488bbe0916de16701268",
            "value": "Map: 100%"
          }
        },
        "1874c5a4b8be43c2940c8274b9e3c69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d91cd8ec83ec48349b274517cba97649",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_603b0d7549b046a4812325b95943dd66",
            "value": 13
          }
        },
        "b2fc44fc2670414096a24e1dfa5253c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da33b7bfa9e4462c95653f35bb7d4fa3",
            "placeholder": "​",
            "style": "IPY_MODEL_774028820a77475bb946ddb938a084e1",
            "value": " 13/13 [00:00&lt;00:00, 330.92 examples/s]"
          }
        },
        "ea55df358d454beaa8d07796dd66ab28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7c33744bb8e45d5a6846e296cc6ad5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7cabeeed2e5488bbe0916de16701268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d91cd8ec83ec48349b274517cba97649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "603b0d7549b046a4812325b95943dd66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da33b7bfa9e4462c95653f35bb7d4fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "774028820a77475bb946ddb938a084e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d7104e82a3340a58b8d53d8c18d4d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a00efaf0ce2542b3b0b5d5ceda0c4232",
              "IPY_MODEL_07d763a20c8c49b3a92ca0fbd7f35c20",
              "IPY_MODEL_303de64ed4bd4bc99227cb7dbacdeb25"
            ],
            "layout": "IPY_MODEL_e57c54d3236f4b7394c959fa897558c9"
          }
        },
        "a00efaf0ce2542b3b0b5d5ceda0c4232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_122ddd70a6ba4c5faf8c3d084de77f54",
            "placeholder": "​",
            "style": "IPY_MODEL_5e22458608ca43d39c39c8fb1e3e9f2e",
            "value": "Map: 100%"
          }
        },
        "07d763a20c8c49b3a92ca0fbd7f35c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de947bd110e54c31bde9c9b460b6543b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a4116e6572140cf89b2d728fc1775e2",
            "value": 1
          }
        },
        "303de64ed4bd4bc99227cb7dbacdeb25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f80819feb450412db226517ed038159c",
            "placeholder": "​",
            "style": "IPY_MODEL_acd91125df1e47ce9d08aa3905463ef1",
            "value": " 1/1 [00:00&lt;00:00, 37.47 examples/s]"
          }
        },
        "e57c54d3236f4b7394c959fa897558c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122ddd70a6ba4c5faf8c3d084de77f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e22458608ca43d39c39c8fb1e3e9f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de947bd110e54c31bde9c9b460b6543b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4116e6572140cf89b2d728fc1775e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f80819feb450412db226517ed038159c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd91125df1e47ce9d08aa3905463ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}