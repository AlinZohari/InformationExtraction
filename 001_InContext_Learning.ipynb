{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-context learning with a pre-trained LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- kor\n",
    "- incontext learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=SW1ZdqH0rRQ&t=872s <br>\n",
    "https://www.youtube.com/watch?v=xZzvwR9jdPA&t=376s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An LLM like GPT-4 can be used as a QA model in a slightly indirect way. For instance, if you give GPT-4 a prompt structured as a question followed by a passage, it may provide an answer, effectively using it in a QA fashion. This isn't due to specialized QA training but rather its general understanding of language and context from its vast training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing LLM model and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing openai and secret key\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Load environment variables from .env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SetO penAI API key from the environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing what gpt model are available for us\n",
    "openai.Model.list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the model you are using in this notebook \n",
    "#model = \"gpt-4-0613\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Insert filename you want to extract information from \n",
    "filename = \"data/authorize_doc/Kuiper_FCC-20-102A1.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here can explain more in kor, a langchain wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries, importing module for langchain and kor\n",
    "\n",
    "#import pandas as pd\n",
    "#from typing import List, Optional\n",
    "\n",
    "#langchain\n",
    "#from langchain.callbacks import get_openai_callback\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "#kor\n",
    "#from kor.extraction import create_extraction_chain\n",
    "#from kor.nodes import Object, Text, Number\n",
    "#from kor import extract_from_documents, from_pydantic, create_extraction_chain\n",
    "\n",
    "#pydantic\n",
    "#from pydantic import BaseModel, Field, validator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.llms import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name= model,\n",
    "    temperature=0,#dont be creative and make up answer\n",
    "    request_timeout= 120,\n",
    "    openai_api_key= openai.api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe the parameter that you choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading, Chunks and Overlap Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the document\n",
    "def import_document(filename):\n",
    "    encodings = ['utf-8', 'ISO-8859-1', 'utf-16', 'ascii', 'cp1252']\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            with open(filename, 'r', encoding=enc) as file:\n",
    "                document_text = file.read()\n",
    "            return document_text\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File '{filename}' not found.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while importing the document: {e}\")\n",
    "            return None\n",
    "    print(f\"Error: Could not decode file with any of the tried encodings: {encodings}\")\n",
    "    return None\n",
    "\n",
    "document = import_document(filename)\n",
    "if document is not None:\n",
    "    print(\"Document content:\")\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's briefly explore the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is token count using textacy\n",
    "import textacy\n",
    "doc = textacy.make_spacy_doc(document, lang=\"en_core_web_sm\")\n",
    "print(doc._.preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy import text_stats as ts\n",
    "\n",
    "# Number of words and number of unique words\n",
    "print(\"Number of words: \", ts.n_words(doc))\n",
    "print(\"Number of unique words: \", ts.n_unique_words(doc))\n",
    "\n",
    "# Entropy of words in the document- measures how much informations produced on the average of the word\n",
    "print(\"Entropy: \", ts.entropy(doc))\n",
    "\n",
    "# Compute the Type-Token Ratio (TTR) of doc_or_token,a direct ratio of the number of unique words (types) of all words (token)\n",
    "print(\"Diversity: \", ts.diversity.ttr(doc))\n",
    "\n",
    "# Flesch Kincaid grade level: readability tests designed to indicate how difficult a passage is\n",
    "print(\"Flesch Kincaid: \",ts.flesch_kincaid_grade_level(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now split the document into chunks and overlap it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the text splitter with specific parameters which are being standardise for all chunking \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,           # Check if this parameter is valid\n",
    "    chunk_overlap=100,        # Check if this parameter is valid\n",
    "    length_function=len,      # Check if this parameter is valid\n",
    "    keep_separator=True       # This is a valid parameter as per the traceback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explaining the parameter if the chunking and overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the document into chunks\n",
    "doc = Document(page_content = document)\n",
    "split_docs = RecursiveCharacterTextSplitter().split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Pydantic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It Kor doumentation it says that the Validation doe NO imply that extraction was correct.\n",
    "Validation only implies that the data was returned in the correct shape and meets all validation criteria.\n",
    "This does not mean that the LLM didn't make up some information\n",
    "\n",
    "we can use pydantic to sip the invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using kor \n",
    "from kor.nodes import Object, Text, Number\n",
    "from kor import extract_from_documents, from_pydantic, create_extraction_chain\n",
    "from kor.extraction import create_extraction_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrbitEnv(BaseModel):\n",
    "    const_name: str = Field(\n",
    "        description=\"The satellite constellation name for which the company applied to deploy or operate\",\n",
    "    )\n",
    "    date_release: str  = Field(\n",
    "        description=\"The date of document release\",\n",
    "    )\n",
    "    date_50: str  = Field(\n",
    "        description=\"The date when the company is order to launch and operate 50 percent of its satellites\",\n",
    "    )\n",
    "    date_100: str  = Field(\n",
    "        description=\"The date when the company is order to completely launch and operate all of its remaining satellites.\",\n",
    "    )\n",
    "    total_sat_const: int = Field(\n",
    "        description=\"The concluding total number of satellites that the company has been authorized to deploy and operate for the constellation\",\n",
    "    )\n",
    "    altitude: Optional[List[float]] = Field(\n",
    "        description=\"The granted altitudes of the satellites that the company has been authorized to deploy\",\n",
    "    )\n",
    "    inclination: Optional[List[float]] = Field(\n",
    "        description=\"The granted inclination of the satellites that the company has been authorized to deploy, respective to the altitudes\",\n",
    "    )\n",
    "    number_orb_plane: Optional[List[int]] = Field(\n",
    "        description=\"The number of orbital planes, respective to the altitudes and inclination, that the company has been authorized to deploy\",\n",
    "    )\n",
    "    total_sat_per_orb_plane: Optional[List[int]] = Field(\n",
    "        description=\"The specific count of satellites located in each individual orbital plane. This count refers to the total number of satellites within one orbital plane, and it can vary from plane to plane based on the altitude and inclination, and if not mentioned in text, 'total_sat_per_alt_incl' divide by 'number_orb_plane' will give this value\",\n",
    "    )\n",
    "    total_sat_per_alt_incl: Optional[List[int]] = Field(\n",
    "        description=\"The total number of satellites at a specific altitude and inclination across all orbital planes sharing these characteristics. This count represents the overall number of satellites with the specified altitude and inclination parameters, and if not mentioned in the text, the multiplication of 'number_orb_plane' and 'total_sat_per_orb_plane' will give this value\",\n",
    "    )\n",
    "    operational_lifetime : Optional[int] = Field(\n",
    "        description=\"The operational lifetime of the satellite in the constellation in years\",\n",
    "    )\n",
    "\n",
    "\n",
    "    @validator(\"const_name\", \"date_release\", \"date_50\", \"date_100\")\n",
    "    def validate_name(cls, v):\n",
    "        if not re.match(\"^[a-zA-Z\\s().,-]*$\", v):\n",
    "            raise ValueError(\"The field can only contain alphabetic characters, spaces, parentheses, periods, commas and hyphen.\")\n",
    "        return v\n",
    "    \n",
    "    @validator(\"total_sat_const\", \"number_orb_plane\", \"total_sat_per_orb_plane\", \"total_sat_per_alt_incl\", \"operational_lifetime\")\n",
    "    def validate_whole_number(cls, v):\n",
    "        if isinstance(v, list):\n",
    "            if not all(isinstance(i, int) for i in v):\n",
    "                raise ValueError(\"All elements of the list must be whole numbers.\")\n",
    "        elif v is not None and not isinstance(v, int):\n",
    "            raise ValueError(\"The field must be a whole number.\")\n",
    "        return v\n",
    "\n",
    "    @validator(\"altitude\", \"inclination\")\n",
    "    def validate_number(cls, v):\n",
    "        if isinstance(v, list):\n",
    "            if not all(isinstance(i, (int, float)) for i in v):\n",
    "                raise ValueError(\"All elements of the list must be numbers (integer or decimal).\")\n",
    "        elif v is not None and not isinstance(v, (int, float)):\n",
    "            raise ValueError(\"The field must be a number (integer or decimal).\")\n",
    "        return v\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Optional[str]' means that the field can be either a str(string) or None effectively making it optional\n",
    "\n",
    "'str' means that it is mandatory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema and Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine-tuning the LLM model using Kor library a wrapper from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema, extraction_validator = from_pydantic(\n",
    "    OrbitEnv,\n",
    "    description=\"Extract the Orbital Environment information of a Satellite Constellation from the provided authorized document. This should encompass details like the satellite constellation name, document release date, dates for both 50 percent and 100 percent satellite launches, total satellite count, altitude, inclination, orbital plane quantity, satellites per orbital plane, satellites per altitude and inclination, as well as the operational lifetime of the satellites.\",\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"In this Order and Authorization, we grant, to the extent set forth below, the request of Kuiper Systems LLC (Kuiper or Amazon) to provide satellite services.\n",
    "                Operating 3,372 satellites in 102 orbital planes at altitudes of 590 km, 610 km, and 630 km in a circular orbit.\n",
    "                At 590 km, 30 orbital planes with 28 satellites per plane for a total of 840 satellites at inclination of 33 degree.\n",
    "                At 610 km, 42 orbital planes with 36 satellites per plane for a total of 1512 satellites at inclination of 42 degree.\n",
    "                At 630 km, 30 orbital planes with 34 satellites per plane for a total of 1020 satellite at inclination of 51.9 degree.\n",
    "                The constellation are require to launch and operate 50 percent of its satellites no later than July 30, 2026, and must launch the remaining space stations necessary to complete its authorized service constellation, place them in their assigned orbits, and operate each of them in accordance with the authorization no later than July 30, 2029.\"\"\",\n",
    "                \n",
    "            {\"const_name\": \"Kuiper\", \"date_50\": \"July 30, 2026\", \"date_100\": \"July 30, 2029\", \"total_sat_const\": 3372, \"altitude\": [590, 610, 630],  \"inclination\": [33, 42, 51.9], \"number_orb_plane\": [30, 42, 30], \"total_sat_per_orb_plane\": [28, 36, 34], \"total_sat_per_alt_incl\": [840, 1512, 1020]}\n",
    "        ),\n",
    "        (\n",
    "            \"Iridium must launch 50 percent of satellite no later than November 12,2028, and must launch the other remaining satellites no later than May 16,2030.\",\n",
    "            {\"const_name\": \"Iridium\",\"date_50\":\"November 12,2028,\",\"date_100\":\"May 16,2030\"}\n",
    "        ),\n",
    "        #date_50 and date_100\n",
    "        (\n",
    "            \"They must launch 50 percent of the maximum number of proposed space stations, place them in the assigned orbits, and operate them in accordance with this grant of U.S. market access no later than December 31,1989, and must launch the remaining space stations necessary to complete its authorized service constellation, place them in their assigned orbits, and operate them in accordance with the grant of U.S. market access no later than December 21,1997.\",\n",
    "            {\"date_50\":\"December 31,1989\",\"date_100\":\"November 21,1997\"}\n",
    "        ),\n",
    "        (\n",
    "            \"The company must launch 50 percent no later than June 22, 2020, and complete its authorized service constellation in accordance with the authorization no later than June 22, 2022. 47 CFR § 25.164(b).\",\n",
    "            {\"date_50\":\"June 22, 2020\",\"date_100\":\"June 22, 2022\"}\n",
    "        ),\n",
    "        (\n",
    "            \"to launch and operate 50 percent of its satellites no later than January 3, 2027, and to complete its authorized service constellation, place them in their assigned orbits, and operate each of them in accordance with the authorization no later than February 13, 2300. 47 CFR § 25.164(b).\",\n",
    "            {\"date_50\":\"January 3, 2027\",\"date_100\":\"February 13, 2300\"}\n",
    "        ),\n",
    "        (\n",
    "            \"In this Order and Declaratory Ruling, we grant in part and defer in part the petition for declaratory ruling of WorldVu Satellites Limited (OneWeb) for modification of its grant of U.S. market access for a its satellite constellation authorized by the United Kingdom. As modified, the constellation will operate with four fewer satellites, reduced from 720 to 716 satellites.\",\n",
    "            {\"const_name\": \"WorldVu Satellites Limited (OneWeb)\", \"total_sat_const\": 716}\n",
    "        ),\n",
    "        (\n",
    "            \"\"\"The proposed Telesat system is set to feature a robust constellation of 124 satellites.\n",
    "            A set of six orbital planes, each inclined at 99.5 degrees, will host nine satellites per plane at an approximate altitude of 1,000 kilometers.\n",
    "            Additionally, seven more orbital planes, each tilted at 37.4 degrees, will carry another group of satellites, with each plane accommodating ten satellites at a higher altitude of approximately 1,248 kilometers.\"\"\",\n",
    "            {\"const_name\": \"Telesat\", \"total_sat_const\": 124, \"altitude\": [1000, 1248], \"inclination\": [99.5, 37.4], \"number_orb_plane\": [6, 7], \"total_sat_per_orb_plane\": [9, 10], \"total_sat_per_alt_incl\": [54, 70]}\n",
    "        ),\n",
    "        #different between total_sat_per_orb_plane and total_sat_per_alt_incl\n",
    "        (\n",
    "            \"20 orbital planes with 28 satellites per plane for a total of 560 satellites at inclination of 33 degree will be placed at an altitude approximately 800 km.\",\n",
    "            {\"altitude\": 800, \"inclination\": 33, \"number_orb_plane\": 20, \"total_sat_per_orb_plane\": 28, \"total_sat_per_alt_incl\": 560}\n",
    "        ),\n",
    "        #total_sat_per_alt_incl = number_orb_plane x total_sat_per_orb_plane\n",
    "        (\n",
    "            \"8 orbital plane containing 15 satellites each which are inclined at 56 degree with altitude of 700 kilometers\",\n",
    "            {\"altitude\": 700, \"inclination\": 56, \"number_orb_plane\": 8, \"total_sat_per_orb_plane\": 15, \"total_sat_per_alt_incl\": 120}\n",
    "        ),\n",
    "        #total_sat_per_orb_plane = total_sat_per_alt_incl x number_orb_plane\n",
    "        (\n",
    "            \"72 of the satellites will be distributed equally and place at 6 orbital planes, which are inclined 99.5 degrees, satellites will be at an approximate altitude of 1,000 kilometers\",\n",
    "            {\"altitude\": 1000, \"inclination\": 99.5, \"number_orb_plane\": 6, \"total_sat_per_orb_plane\": 12, \"total_sat_per_alt_incl\": 72}\n",
    "        ),\n",
    "        #operational_lifetime\n",
    "        (\n",
    "            \"The operational lifetime for the satellite in the constellation in 10 years\",\n",
    "            {\"operational_lifetime\": 10}\n",
    "        ),\n",
    "        #date release\n",
    "        (\n",
    "            \"Released:  March 29, 2010\",\n",
    "            {\"date_release\": \"March 29, 2010\"}\n",
    "        ),\n",
    "        (\n",
    "            \"Released:  November 21,1997\",\n",
    "            {\"date_release\": \"Noember 21,1997\"}\n",
    "        ),\n",
    "\n",
    "    ],\n",
    "    many=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will provide more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" #maneuverable and spin-stabilized\n",
    "(\n",
    "    \"\"\"Each satellite in the constellation is equipped with propulsion, enabling it to perform maneuvers to avoid collisions and navigate to its designated operational orbit.\n",
    "    Additionally, the satellites also have spin stabilizers, ensuring their stability during orbital operation.\"\"\",\n",
    "    {\"maneuverable\": \"y\", \"spin_stabilized\": \"y\"}\n",
    "), \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'many' parameter determine whether the funciton should expect to work with a single instance of the object or multiple instances\n",
    "\n",
    "- If many=False (the default), the schema expects to validate a single object of the class defined in the function call (OrbitEnv in your case).\n",
    "- If many=True, the schema expects to validate a list of objects of the class defined in the function call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can explain more on the concept of a chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_extraction_chain(\n",
    "    llm,\n",
    "    schema,\n",
    "    encoder_or_encoder_class=\"json\",\n",
    "    validator=extraction_validator,\n",
    "    input_formatter=\"triple_quotes\",\n",
    ")\n",
    "\n",
    "#csv does support list , but json is not as accurate as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at what are the prompt and istruction pass to the LLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by using kor, it already setup with a system message as a prompt on what to do providing it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.prompt.format_prompt(text=\"[user input]\").to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seeing how much it cost us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seeing the raw return of iterating 5 times. The iteration are done because the nherentrandomness and non-deterministic nature of certain aspect of LLMs model behaviour. LLMs exhibit variability in their outputs because:\n",
    "1. Stochastic Processess in Training: (stochastic - having random probability distribution or pattern that may be analysed statistically but may not be predicted precisely) various stochastic process involve are weight initialization, gradient descent optimizationn and dropout which introduce randomness into the learning process, leading to slight differences in the model's internal representations and learned parameters\n",
    "2. Attention Mechanism: if the LLM are based on Transformer architecture,use attention mechanisms to weigh the importance of different words in a sentence. These attention weights are often computed stochastically, which means that different runs or queries might result in slightly different attention distributions. These variations can influence the model's understanding of context and the words it attends to.\n",
    "3. Random Intiialization: LLMs are initialized with random weights before training. Since these initial weights impact the learning trajectory of the model, variations in initialization can lead to differences in how the model learns and generalizes.\n",
    "4. Sampling strategies: When generating responses, LLMs often use sampling techniques like \"greedy decoding\" (choosing the most likely word) or \"random sampling\" (sampling from the probability distribution). These strategies can introduce variability in the generated outputs, as different sampling choices can result in different sequences of words.\n",
    "5. Temperature Parameter: Some LLMs use a \"temperature\" parameter during the sampling process. Higher values make the distribution over words more uniform, while lower values emphasize high-probability words. Adjusting this parameter can influence the diversity and randomness of generated text.\n",
    "6. Random Seed and Environment: The initial random seed and the environment in which the LLM is executed can also impact its behavior. Different seeds or execution environments can lead to divergent paths during the generation process.\n",
    "7. Contextual Embeddings: LLMs use contextual embeddings, which capture information from the entire input sequence. However, small perturbations in the input can lead to slightly different contextual embeddings, resulting in variations in the generated outputs.\n",
    "8. Model Architecture: Some LLMs have specific architectural choices that introduce randomness, such as dropout layers, which randomly drop out units during training to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_results = []\n",
    "\n",
    "for i in range(5):\n",
    "    with get_openai_callback() as cb:\n",
    "        document_extraction_result = await extract_from_documents(\n",
    "            chain, split_docs, max_concurrency=5, use_uid=False, return_exceptions=True\n",
    "        )\n",
    "        iteration_results.append(document_extraction_result)\n",
    "        \n",
    "        # Print some statistics for each iteration\n",
    "        print(f\"Iteration {i + 1}:\")\n",
    "        print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "        print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "        print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "        print(f\"Successful Requests: {cb.successful_requests}\")\n",
    "        print(f\"Total Cost (USD): ${cb.total_cost}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_dataframe_from_iterations(iteration_data):\n",
    "    # Prepare an empty list to store all OrbitEnv data\n",
    "    data = []\n",
    "\n",
    "    # Loop through each iteration's data\n",
    "    for json_data in iteration_data:\n",
    "        for record in json_data:\n",
    "            # Check if the record is a dictionary. If not, print an error and continue to the next record\n",
    "            if not isinstance(record, dict):\n",
    "                print(f\"Error encountered: {record}\")\n",
    "                continue\n",
    "\n",
    "            orbitenv_list = record.get('data', {}).get('orbitenv', [])\n",
    "            for orbitenv in orbitenv_list:\n",
    "                data.append([\n",
    "                    orbitenv.get('const_name', ''),\n",
    "                    orbitenv.get('date_release', ''),\n",
    "                    orbitenv.get('date_50', ''),\n",
    "                    orbitenv.get('date_100', ''),\n",
    "                    orbitenv.get('total_sat_const', ''),\n",
    "                    orbitenv.get('altitude', '') or '',\n",
    "                    orbitenv.get('inclination', '') or '',\n",
    "                    orbitenv.get('number_orb_plane', '') or '',\n",
    "                    orbitenv.get('total_sat_per_orb_plane', '') or '',\n",
    "                    orbitenv.get('total_sat_per_alt_incl', '') or '',\n",
    "                    orbitenv.get('operational_lifetime', '')\n",
    "                ])\n",
    "\n",
    "    # Convert the list into a DataFrame\n",
    "    df = pd.DataFrame(data, columns=['constellationName', 'dateRelease', 'date50', 'date100', 'totalSatelliteNumber', 'altitudes','inclination', 'numberOrbPlane', 'totalSatellitePerOrbPlane','totalSatellitePerAltIncl','operationalLifetime'])\n",
    "\n",
    "    # Replace various values with None\n",
    "    df.replace(['','-',0,'Null', 'null', 'Not Mentioned', 'Not mentioned', 'not mentioned', 'unknown', 'Unknown','N/A'], None, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming iteration_results is the list that holds the results from the 5 iterations\n",
    "# df = generate_dataframe_from_iterations(iteration_results)\n",
    "\n",
    "df = generate_dataframe_from_iterations(iteration_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent in Each Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def find_most_frequent(df: pd.DataFrame) -> dict:\n",
    "    most_frequent_dict = {}\n",
    "    for column in df.columns:\n",
    "        column_without_none = df[column].dropna()\n",
    "        if not column_without_none.empty:\n",
    "            mode = column_without_none.mode()\n",
    "            if len(mode) > 1:\n",
    "                most_frequent_dict[column] = {\"message\": \"Multiple modes found\", \"modes\": mode.tolist()}\n",
    "            else:\n",
    "                most_frequent_dict[column] = mode[0]\n",
    "        else:\n",
    "            most_frequent_dict[column] = None\n",
    "    return most_frequent_dict\n",
    "\n",
    "def convert(o):\n",
    "    if isinstance(o, np.generic):\n",
    "        return o.item()\n",
    "    raise TypeError\n",
    "\n",
    "def convert_to_json(data: dict) -> str:\n",
    "    try:\n",
    "        json_data = json.dumps(data, default=convert)\n",
    "        return json_data\n",
    "    except TypeError:\n",
    "        return json.dumps({\"error\": \"Failed to serialize data\"})\n",
    "\n",
    "result = find_most_frequent(df)\n",
    "result\n",
    "#returninng dictionary key-value pair, mutable , can be add, remove, change element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do and if statement here to find date_500 and date_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to Json and exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = convert_to_json(result)\n",
    "\n",
    "name = result.get('constellationName', {}).get('modes', [None])[0] if isinstance(result.get('constellationName', {}), dict) else result.get('constellationName', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if name is not None:\n",
    "    name = re.sub(r'\\W+', '_', name)\n",
    "    filename = f'output/{name}_{model}_data.json'\n",
    "\n",
    "    with open(filename, 'w+') as txt_file:\n",
    "        txt_file.write(json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yet to do\n",
    "- for the total number of satellite in constellation you can do if there are multiple mode found match the value with the sum of all array in total number of satellite (per altitude/inclination) - if it match that is your total number of satellite in constellation\n",
    "- adding in maneuverable and spin stabilisation as a field and operational lifetime - manueverable and stabilisation is really hard to get it right - also add orbit epoch\n",
    "- using different LLM model\n",
    "- using different company order authorize document -done\n",
    "- using different type of document - schedule S or techical document\n",
    "- how to measure validation (intrisic and extrinsic) - validate if the extracted info is in and at what paragraph - or hallucination\n",
    "- make this a model? - putting input text - output json fresh  - calculation coding - true process all column 29\n",
    "\n",
    "- maybe before doing extraction - do a sentiment analysis for the whole document - to see if the purpose constallation are fully granted, partially granted ot denied \n",
    "\n",
    "- need to extract also the release date\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
